Aggarwal, N., Prakash, N., and Sofat, S. 2010. Content management system effort estimation using bagging predictors. In Proceedings of the International Joint Conference on Computer Information Systems Sciences and Engineering Technological Developments in Education and Automation, M. Iskander, V. Kapila, and M. Karim, Eds. 19--24.
Aha, D. W. and Bankert, R. L. 1996. A comparative evaluation of sequential feature selection algorithms. In Learning from Data, D. Fisher and H.-J. Lenz, Eds. Springer, Chapter 4, 199--206.
Matti Aksela, Comparison of classifier selection methods for improving committee performance, Proceedings of the 4th international conference on Multiple classifier systems, June 11-13, 2003, Guildford, UK
Al-Ani, A. 2005. Feature subset selection using ant colony optimization. Int. J. Comput. Intell. 2, 1, 53--58.
Ran Avnimelech , Nathan Intrator, Boosting regression estimators, Neural Computation, v.11 n.2, p.499-520, Feb. 15, 1999[doi>10.1162/089976699300016746]
Paulo J. Azevedo , Alípio M. Jorge, Iterative reordering of rules for building ensembles without relearning, Proceedings of the 10th international conference on Discovery science, October 01-04, 2007, Sendai, Japan
Paulo J. Azevedo , Alípio Mário Jorge, Ensembles of jittered association rule classifiers, Data Mining and Knowledge Discovery, v.21 n.1, p.91-129, July      2010[doi>10.1007/s10618-010-0173-y]
Bart Bakker , Tom Heskes, Clustering ensembles of neural network models, Neural Networks, v.16 n.2, p.261-269, March 2003[doi>10.1016/S0893-6080(02)00187-9]
Jon Louis Bentley, Multidimensional binary search trees used for associative searching, Communications of the ACM, v.18 n.9, p.509-517, Sept. 1975[doi>10.1145/361002.361007]
George B. Bezerra , Tiago V. Barra , Leandro N. de Castro , Fernando J. Von Zuben, Adaptive radius immune algorithm for data clustering, Proceedings of the 4th international conference on Artificial Immune Systems, August 14-17, 2005, Banff, Alberta, Canada[doi>10.1007/11536444_22]
Albert Bifet , Geoff Holmes , Bernhard Pfahringer , Richard Kirkby , Ricard Gavaldà, New ensemble methods for evolving data streams, Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, June 28-July 01, 2009, Paris, France[doi>10.1145/1557019.1557041]
Hendrik Blockeel , Joaquin Vanschoren, Experiment Databases: Towards an Improved Experimental Methodology in Machine Learning, Proceedings of the 11th European conference on Principles and Practice of Knowledge Discovery in Databases, September 17-21, 2007, Warsaw, Poland[doi>10.1007/978-3-540-74976-9_5]
Simone Borra , Agostino Di Ciaccio, Improving nonparametric regression methods by bagging and boosting, Computational Statistics & Data Analysis, v.38 n.4, p.407-420, 28 February 2002[doi>10.1016/S0167-9473(01)00068-8]
Pavel Brazdil, Metalearning: Applications to Data Mining, Springer-Verlag, Berlin, Heidelberg, 2009
Leo Breiman, Bagging predictors, Machine Learning, v.24 n.2, p.123-140, Aug. 1996[doi>10.1023/A:1018054314350]
Breiman, L. 1996b. Heuristics of instability and stabilization in model selection. Ann. Statist. 24, 6, 2350--2383.
Leo Breiman, Stacked regressions, Machine Learning, v.24 n.1, p.49-64, July 1996[doi>10.1023/A:1018046112532]
Leo Breiman, Randomizing Outputs to Increase Prediction Accuracy, Machine Learning, v.40 n.3, p.229-242, Sept. 2000[doi>10.1023/A:1007682208299]
Leo Breiman, Random Forests, Machine Learning, v.45 n.1, p.5-32, October 1 2001[doi>10.1023/A:1010933404324]
Leo Breiman, Using Iterated Bagging to Debias Regressions, Machine Learning, v.45 n.3, p.261-277, December 2001[doi>10.1023/A:1017934522171]
Brown, G. 2004. Diversity in neural network ensembles. Ph.D. thesis, University of Birmingham.
Brown, G., Wyatt, J. L., Harris, R., and Yao, X. 2005a. Diversity creation methods: A survey and categorisation. Inf. Fusion 6, 5--20.
Gavin Brown , Jeremy L. Wyatt , Peter Tiňo, Managing Diversity in Regression Ensembles, The Journal of Machine Learning Research, 6, p.1621-1650, 12/1/2005
Buhlmann, P. 2010. Bagging, Boosting and Ensemble Methods. Springer.
Buja, A. and Stuetzle, W. 2006. Observations on bagging. Statistica Sinica 16, 323--351.
Cai, T. and Wu, X. 2008. Research on ensemble learning based on discretization method. In Proceedings of the 9<sup>th</sup> International Conference on Signal Processing (ICSP'08). 1528--1531.
Rich Caruana , Alexandru Niculescu-Mizil , Geoff Crew , Alex Ksikes, Ensemble selection from libraries of models, Proceedings of the twenty-first international conference on Machine learning, p.18, July 04-08, 2004, Banff, Alberta, Canada[doi>10.1145/1015330.1015432]
Coelho, G. P. and von Zuben, F. J. 2006. The influence of the pool of candidates on the performance of selection and combination techniques in ensembles. In Proceedings of the International Joint Conference on Neural Networks. 10588--10595.
Delve. 2002. Delve: Data for evaluating learning in valid experiments. http://www.cs.toronto.edu/~delve/
Didaci. L. and Giacinto, G. 2004. Dynamic classifier selection by adaptive k-nearest neighbourhood rule. In Proceedings of the International Workshop on Multiple Classifier Systems, F. Roli, J. Kittler, and T. Windeatt, Eds. Lecture Notes in Computer Science, vol. 3077. Springer, 174--183.
Dietterich, T. G. 1997. Machine-Learning research: Four current directions. AI Mag. 18, 4, 97--136.
Carlotta Domeniconi , Bojun Yan, Nearest Neighbor Ensemble, Proceedings of the Pattern Recognition, 17th International Conference on (ICPR'04) Volume 1, p.228-231, August 23-26, 2004[doi>10.1109/ICPR.2004.612]
Domingos, P. 1997. Why does bagging work&quest; A Bayesian account and its implications. In Proceedings of the International Conference on Knowledge Discovery and Data Mining. AAAI Press, 155--158.
Harris Drucker, Improving Regressors using Boosting Techniques, Proceedings of the Fourteenth International Conference on Machine Learning, p.107-115, July 08-12, 1997
Nigel Duffy , David Helmbold, Boosting Methods for Regression, Machine Learning, v.47 n.2-3, p.153-200, May-June 2002[doi>10.1023/A:1013685603443]
Luciana Ferrer , Kemal Sönmez , Elizabeth Shriberg, An Anticorrelation Kernel for Subsystem Training in Multiple Classifier Systems, The Journal of Machine Learning Research, 10, p.2079-2114, 12/1/2009
Flannagan, S. and Sperber, L. 2008. Datamob/datasets. http://datamob.org/datsets
Frank, A. and Asuncion, A. 2010. UCI machine learning repository. http://archive.ics.uci.edu/ml
Eibe Frank , Bernhard Pfahringer, Improving on bagging with input smearing, Proceedings of the 10th Pacific-Asia conference on Advances in Knowledge Discovery and Data Mining, April 09-12, 2006, Singapore[doi>10.1007/11731139_14]
Freund, Y. and Schapire, R. 1996. Experiments with a new boosting algorithm. In Proceedings of the International Conference on Machine Learning. 148--156.
Yoav Freund , Robert E. Schapire, A decision-theoretic generalization of on-line learning and an application to boosting, Journal of Computer and System Sciences, v.55 n.1, p.119-139, Aug. 1997[doi>10.1006/jcss.1997.1504]
Friedman, J. H. 1991. Multivariate adaptive regression splines. The Ann. Statist. 19, 1, 1--141.
Friedman, J. H. 1996. Local learning based on recursive covering. Tech. rep.
Friedman, J. H. 2001. Greedy function approximation: A gradient boosting machine. Ann. Statist. 29, 5, 1189--1232.
Jerome H. Friedman, Stochastic gradient boosting, Computational Statistics & Data Analysis, v.38 n.4, p.367-378, 28 February 2002[doi>10.1016/S0167-9473(01)00065-2]
Friedman, H. H. and Stuetzle, W. 1981. Projection pursuit regression. J. Amer. Statist. Regress. 76, 376, 817--823.
N. Garcia-Pedrajas , C. Hervas-Martinez , D. Ortiz-Boyer, Cooperative coevolution of artificial neural network ensembles for pattern classification, IEEE Transactions on Evolutionary Computation, v.9 n.3, p.271-302, June 2005[doi>10.1109/TEVC.2005.844158]
Stuart Geman , Elie Bienenstock , René Doursat, Neural networks and the bias/variance dilemma, Neural Computation, v.4 n.1, p.1-58, Jan. 1992[doi>10.1162/neco.1992.4.1.1]
Giorgio Giacinto , Fabio Roli, Adaptive Selection of Image Classifiers, Proceedings of the 9th International Conference on Image Analysis and Processing-Volume I, p.38-45, September 17-19, 1997
P. M. Granitto , P. F. Verdes , H. A. Ceccatto, Neural network ensembles: evaluation of aggregation algorithms, Artificial Intelligence, v.163 n.2, p.139-162, April 2005[doi>10.1016/j.artint.2004.09.006]
Guvenir, H. A, and Uysal, I. 2000. Function approximation repository. http://funapp.cs.bilkent.edu. tr/DataSets/
Sherif Hashem, Optimal linear combinations of neural networks, Purdue University, West Lafayette, IN, 1993
Trevor Hastie , Robert Tibshirani, Discriminant Adaptive Nearest Neighbor Classification, IEEE Transactions on Pattern Analysis and Machine Intelligence, v.18 n.6, p.607-616, June 1996[doi>10.1109/34.506411]
Hastie, T., Tibshirani, R., and Friedman, J. H. 2001. The Elements of Statistical Learning: Data Mining, Inference, and Predictions. Springer Series in Statistics. Springer.
Hernández-Lobato, D., Martínez-Muñoz, G., and Suárez, A. 2006. Pruning in ordered regression bagging ensembles. In Proceedings of the International Joint Conference on Neural Networks. 1266--1273.
Tin Kam Ho, The Random Subspace Method for Constructing Decision Forests, IEEE Transactions on Pattern Analysis and Machine Intelligence, v.20 n.8, p.832-844, August 1998[doi>10.1109/34.709601]
Md. M. Islam , Xin Yao , K. Murase, A constructive algorithm for training cooperative neural network ensembles, IEEE Transactions on Neural Networks, v.14 n.4, p.820-834, July 2003[doi>10.1109/TNN.2003.813832]
Anil Jain , Douglas Zongker, Feature Selection: Evaluation, Application, and Small Sample Performance, IEEE Transactions on Pattern Analysis and Machine Intelligence, v.19 n.2, p.153-158, February 1997[doi>10.1109/34.574797]
Alípio M. Jorge , Paulo J. Azevedo, An experiment with association rules and classification: post-bagging and conviction, Proceedings of the 8th international conference on Discovery Science, October 08-11, 2005, Singapore[doi>10.1007/11563983_13]
Kim, H.-C., Pang, S., Je, H.-M., Kim, D., and Bang, S.-Y. 2003. Constructing support vector machine ensemble. Pattern Recogn. 36, 12, 2757--2767.
Jyrki Kivinen , Manfred K. Warmuth, Exponentiated gradient versus gradient descent for linear predictors, Information and Computation, v.132 n.1, p.1-63, Jan. 10, 1997[doi>10.1006/inco.1996.2612]
Albert H. R. Ko , Robert Sabourin , Alceu Souza Britto, Jr., From dynamic classifier selection to dynamic ensemble selection, Pattern Recognition, v.41 n.5, p.1718-1731, May, 2008[doi>10.1016/j.patcog.2007.10.015]
Kolen, J. F. and Pollack, J. B. 1990. Back propagation is sensitive to initial conditions. Tech. rep. TR-90-JK-BPSIC, The Ohio State University.
J. Zico Kolter , Marcus A. Maloof, Dynamic Weighted Majority: An Ensemble Method for Drifting Concepts, The Journal of Machine Learning Research, 8, p.2755-2790, 12/1/2007
Kotsiantis, S. and Pintelas, P. 2005. Selective averaging of regression models. Ann. Math. Comput. Teleinf. 1, 3, 65--74.
Krogh, A. and Vedelsby, J. 1995. Neural network ensembles, cross validation, and active learning. Adv. Neural Inf. Process. Syst. 7, 231--238.
L. I. Kuncheva, Switching between selection and fusion in combining classifiers: an experiment, IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, v.32 n.2, p.146-156, April 2002[doi>10.1109/3477.990871]
Ludmila I. Kuncheva, Combining Pattern Classifiers: Methods and Algorithms, Wiley-Interscience, 2004
Tadeusz Lasota , Zbigniew Telec , Bogdan Trawiński , Krzysztof Trawiński, A Multi-agent System to Assist with Real Estate Appraisals Using Bagging Ensembles, Proceedings of the 1st International Conference on Computational Collective Intelligence. Semantic Web, Social Networks and Multiagent Systems, October 05-07, 2009, WrocBaw, Poland[doi>10.1007/978-3-642-04441-0_71]
Lazarevic, A. 2001. Effective pruning of neural network classifier ensembles. In Proceedings of the International Joint Conference on Neural Networks. 796--801.
LeBlanc, M. and Tibshirani, R. 1996. Combining estimates in regression and classification. J. Amer. Statist. Assoc. 91, 1641--1650.
Lehmann, E. 1998. Theory of Point Estimation. Springer.
Hsuan-Tien Lin , Ling Li, Infinite ensemble learning with support vector machines, Proceedings of the 16th European conference on Machine Learning, October 03-07, 2005, Porto, Portugal[doi>10.1007/11564096_26]
Y. Liu , X. Yao, Ensemble learning via negative correlation, Neural Networks, v.12 n.10, p.1399-1404, Dec. 1999[doi>10.1016/S0893-6080(99)00073-8]
Yong Liu , Xin Yao , T. Higuchi, Evolutionary ensembles with negative correlation learning, IEEE Transactions on Evolutionary Computation, v.4 n.4, p.380-387, November 2000[doi>10.1109/4235.887237]
Loughrey, J. and Cunningham, P. 2005. Using early stopping to reduce overfitting in wrapper-based feature weighting. Tech. rep. TCD-CS-2005-41, Trinity College Dublin, Computer Science Department.
Dragos D. Margineantu , Thomas G. Dietterich, Pruning Adaptive Boosting, Proceedings of the Fourteenth International Conference on Machine Learning, p.211-218, July 08-12, 1997
Gonzalo Martínez-Muñoz , Daniel Hernández-Lobato , Alberto Suárez, An Analysis of Ensemble Pruning Techniques Based on Ordered Aggregation, IEEE Transactions on Pattern Analysis and Machine Intelligence, v.31 n.2, p.245-259, February 2009[doi>10.1109/TPAMI.2008.78]
Gonzalo Martínez-Muñoz , Alberto Suárez, Pruning in ordered bagging ensembles, Proceedings of the 23rd international conference on Machine learning, p.609-616, June 25-29, 2006, Pittsburgh, Pennsylvania[doi>10.1145/1143844.1143921]
Gonzalo Martínez-Muñoz , Alberto Suárez, Using boosting to prune bagging ensembles, Pattern Recognition Letters, v.28 n.1, p.156-165, January, 2007[doi>10.1016/j.patrec.2006.06.018]
Randall Matignon, Data Mining Using SAS Enterprise Miner (Wiley Series in Computational Statistics), Wiley-Interscience, 2007
Mendes-Moreira, J. 2008. Travel time prediction for the planning of mass transit companies: A machine learning approach. Ph.D. thesis, Faculty of Engineering, University of Porto.
Mendes-Moreira, J., Jorge, A. M., Freire de Sousa, J., and Soares, C. 2012. Comparing state-of-the-art regression methods for long term travel time prediction. Intell. Data Anal. 16, 3.
João Mendes-Moreira , Alipio Mario Jorge , Carlos Soares , Jorge Freire Sousa, Ensemble Learning: A Study on Different Variants of the Dynamic Selection Approach, Proceedings of the 6th International Conference on Machine Learning and Data Mining in Pattern Recognition, July 23-25, 2009, Leipzig, Germany[doi>10.1007/978-3-642-03070-3_15]
Gaofeng Meng , Chunhong Pan , Nanning Zheng , Chen Sun, Skew estimation of document images using bagging, IEEE Transactions on Image Processing, v.19 n.7, p.1837-1846, July 2010[doi>10.1109/TIP.2010.2045677]
Merz, C. J. 1996. Dynamical selection of learning algorithms. In Proceedings of the International Workshop on Artificial Intelligence and Statistics, D. Fisher and H.-J. Lenz, Eds. Springer.
Christopher John Merz , Michael J. Pazzani, Classification and regression by combining models, University of California, Irvine, 1998
Christopher J. Merz , Michael J. Pazzani, A Principal Components Approach to Combining Regression Estimates, Machine Learning, v.36 n.1-2, p.9-32, July-August 1999[doi>10.1023/A:1007507221352]
Meyer, D., Leisch, F., and Hornik, K. 2003. The support vector machine under test. Neurocomput. 55, 1--2, 169--186.
MLG, U. D. 2011. http://mlg.ucd.ie/
Luis Carlos Molina , Lluís Belanche , Àngela Nebot, Feature Selection Algorithms: A Survey and Experimental Evaluation, Proceedings of the 2002 IEEE International Conference on Data Mining, p.306, December 09-12, 2002
Stefano Monti , Pablo Tamayo , Jill Mesirov , Todd Golub, Consensus Clustering: A Resampling-Based Method for Class Discovery and Visualization of Gene Expression Microarray Data, Machine Learning, v.52 n.1-2, p.91-118, July-August 2003[doi>10.1023/A:1023949509487]
Moreira, J. M., Sousa, J. F., Jorge, A. M., and Soares, C. 2006. An ensemble regression approach for bus trip time prediction. In Proceedings of the Meeting of the EURO Working Group on Transportation. 317--321. http://www.liaad.up.pt/~amjorge/docs/Triana/Moreira06b.pdf.
Il-Seok Oh , Jin-Seon Lee , Byung-Ro Moon, Hybrid Genetic Algorithms for Feature Selection, IEEE Transactions on Pattern Analysis and Machine Intelligence, v.26 n.11, p.1424-1437, November 2004[doi>10.1109/TPAMI.2004.105]
David W. Opitz, Feature selection for ensembles, Proceedings of the sixteenth national conference on Artificial intelligence and the eleventh Innovative applications of artificial intelligence conference innovative applications of artificial intelligence, p.379-384, July 18-22, 1999, Orlando, Florida, USA
Opitz, D. W. and Shavlik, J. W. 1996. Generating accurate and diverse members of a neural-network ensemble. Adv. Neural Inf. Process. Syst. 8, 535--541.
Domingo Ortiz-Boyer , César HerváMartínez , Nicolás García-Pedrajas, CIXL2: a crossover operator for evolutionary algorithms based on population features, Journal of Artificial Intelligence Research, v.24 n.1, p.1-48, July 2005
Parmanto, B., Munro, P, W., and Doyle, H. R. 1996. Reducing variance of committee prediction with resampling techniques. Connect. Sci. 8, 3--4, 405--425.
D. Partridge , W. B. Yates, Engineering multiversion neural-net systems, Neural Computation, v.8 n.4, p.869-893, May 15, 1996[doi>10.1162/neco.1996.8.4.869]
Perrone, M. P. and Cooper, L. N. 1993. When networks disagree: Ensemble methods for hybrid neural networks. In Neural Networks for Speech and Image Processing, R. Mammone, Ed. Chapman-Hall.
Polikar, R. 2009. Ensemble learning. Scholarpedia 4, 1, 2776.
Pudil, P., Ferri, F., Novovicova, J., and Kittler, J. 1994. Floating search methods for feature selection with nonmonotonic criterion functions. In Proceedings of the IEEE International Conference on Pattern Recognition. Vol. 11. 279--283.
Seppo Puuronen , Vagan Y. Terziyan , Alexey Tsymbal, A Dynamic Integration Algorithm for an Ensemble of Classifiers, Proceedings of the 11th International Symposium on Foundations of Intelligent Systems, p.592-600, June 08-11, 1999
Romesh Ranawana , Vasile Palade, Multi-Classifier Systems: Review and a roadmap for developers, International Journal of Hybrid Intelligent Systems, v.3 n.1, p.35-61, January 2006
Gunnar Rätsch , Ayhan Demiriz , Kristin P. Bennett, Sparse Regression Ensembles in Infinite and Finite Hypothesis Spaces, Machine Learning, v.48 n.1-3, p.189-218, 2002[doi>10.1023/A:1013907905629]
Raviv, Y. and Intrator, N. 1996. Bootstrapping with noise: An effective regularization technique. Connect. Sci. 8, 3--4, 355--372.
Robnik-Sikonja, M. 2004. Improving random forests. In Proceedings of the European Conference on Machine Learning. Lecture Notes in Artificial Intelligence, vol. 3201. Springer, 359--370.
Marko Robnik-Šikonja , Igor Kononenko, Theoretical and Empirical Analysis of ReliefF and RReliefF, Machine Learning, v.53 n.1-2, p.23-69, October-November 2003[doi>10.1023/A:1025667309714]
Juan J. Rodriguez , Ludmila I. Kuncheva , Carlos J. Alonso, Rotation Forest: A New Classifier Ensemble Method, IEEE Transactions on Pattern Analysis and Machine Intelligence, v.28 n.10, p.1619-1630, October 2006[doi>10.1109/TPAMI.2006.211]
Lior Rokach, Collective-agreement-based pruning of ensembles, Computational Statistics & Data Analysis, v.53 n.4, p.1015-1026, February, 2009[doi>10.1016/j.csda.2008.12.001]
Lior Rokach, Pattern Classification Using Ensemble Methods, World Scientific Publishing Co., Inc., River Edge, NJ, 2010
Lior Rokach, Taxonomy for characterizing ensemble methods in classification tasks: A review and annotated bibliography, Computational Statistics & Data Analysis, v.53 n.12, p.4046-4072, October, 2009[doi>10.1016/j.csda.2009.07.017]
Lior Rokach, Ensemble-based classifiers, Artificial Intelligence Review, v.33 n.1-2, p.1-39, February  2010[doi>10.1007/s10462-009-9124-7]
Fabio Roli , Giorgio Giacinto , Gianni Vernazza, Methods for Designing Multiple Classifier Systems, Proceedings of the Second International Workshop on Multiple Classifier Systems, p.78-87, July 02-04, 2001
Niall Rooney , David Patterson, Rapid and brief communication: A weighted combination of stacking and dynamic integration, Pattern Recognition, v.40 n.4, p.1385-1388, April, 2007[doi>10.1016/j.patcog.2006.10.008]
Rooney, N., Patterson, D., Anand, S., and Tsymbal, A. 2004. Dynamic integration of regression models. In Proceedings of the International Workshop on Multiple Classifier Systems. Lecture Notes in Computer Science, vol. 3181. Springer, 164--173.
Rosen, B. E. 1996. Ensemble learning using decorrelated neural networks. Connect. Sci. 8, 3--4, 373--383.
Dymitr Ruta , Bogdan Gabrys, Application of the Evolutionary Algorithms for Classifier Selection in Multiple Classifier Systems with Majority Voting, Proceedings of the Second International Workshop on Multiple Classifier Systems, p.399-408, July 02-04, 2001
Robert E. Schapire, The Strength of Weak Learnability, Machine Learning, v.5 n.2, p.197-227, Jun. 1990[doi>10.1023/A:1022648800760]
Schclar, A. and Rokach, L. 2009. Random projection ensemble classifiers. In Proceedings of the International Conference on Enterprise Information Systems (ICEIS'09). Springer.
Alon Schclar , Alexander Tsikinovsky , Lior Rokach , Amnon Meisels , Liat Antwarg, Ensemble methods for improving the performance of neighborhood-based collaborative filtering, Proceedings of the third ACM conference on Recommender systems, October 23-25, 2009, New York, New York, USA[doi>10.1145/1639714.1639763]
D. L. Shrestha , D. P. Solomatine, Experiments with AdaBoost.RT, an improved boosting scheme for regression, Neural Computation, v.18 n.7, p.1678-1710, July 2006[doi>10.1162/neco.2006.18.7.1678]
Skalak, D. B. 1994. Prototype and feature selection by sampling and random mutation hill climbing algorithms. In Proceedings of the International Conference on Machine Learning. Morgan Kaufmann, 293--301.
Skomoroch, P. 2008. Some datasets available on the web. http://www.datawrangling.com/some-datasets-available-on-the-web
Stark, P. and Parker, R. 1995. Bounded-Variable least squares: An algorithm and applications. Comput. Statist. 10, 2, 129--141.
Stone, M. 1974. Cross-Validatory choice and assessment of statistical predictions. J. Roy. Statist. Soc. B36, 2, 111--147.
Alexander Strehl , Joydeep Ghosh, Cluster ensembles --- a knowledge reuse framework for combining multiple partitions, The Journal of Machine Learning Research, 3, p.583-617, 3/1/2003[doi>10.1162/153244303321897735]
Christino Tamon , Jie Xiang, On the Boosting Pruning Problem, Proceedings of the 11th European Conference on Machine Learning, p.404-412, May 31-June 02, 2000
Thompson, S. K. and Seber, G. A. 1986. Adaptive Sampling. John Wiley & Sons.
Tian, J., Wu, N., Chu, X., and Fan, Y. 2010. Predicting changes in protein thermostability brought about by single- or multi-site mutations. BMC Bioinf. 11, 370.
Ljupčo Todorovski , Sašo Džeroski, Combining Classifiers with Meta Decision Trees, Machine Learning, v.50 n.3, p.223-249, March 2003[doi>10.1023/A:1021709817809]
Torgo, L. Regression datasets. http://www.liaad.up.pt/ltorgo/Regression/Datasets.html.
Tresp, V. and Taniguchi, M. 1995. Combining estimators using non-constant weighting functions. Adv. Neural Inf. Process. Syst. 7, 419--426.
Ivor W. Tsang , Andras Kocsor , James T. Kwok, Diversified SVM ensembles for large data sets, Proceedings of the 17th European conference on Machine Learning, September 18-22, 2006, Berlin, Germany[doi>10.1007/11871842_81]
Ivor W. Tsang , James T. Kwok , Kimo T. Lai, Core Vector Regression for very large regression problems, Proceedings of the 22nd international conference on Machine learning, p.912-919, August 07-11, 2005, Bonn, Germany[doi>10.1145/1102351.1102466]
Tsoumakas, G., Partalas, I., and Vlahavas, I. 2008. A taxonomy and short review of ensemble selection. In Proceedings of the Workshop on Supervised and Unsupervised Ensemble Methods and Their Applications.
Alexey Tsymbal , Mykola Pechenizkiy , Pádraig Cunningham, Dynamic integration with random forests, Proceedings of the 17th European conference on Machine Learning, September 18-22, 2006, Berlin, Germany[doi>10.1007/11871842_82]
Tsymbal, A., Pechenizkiy, M., and Cunningham, P. 2006b. Dynamic integration with random forests. Tech. rep. TCD-CS-2006-23, The University of Dublin, Trinity College.
Alexey Tsymbal , Mykola Pechenizkiy , Pádraig Cunningham , Seppo Puuronen, Dynamic integration of classifiers for handling concept drift, Information Fusion, v.9 n.1, p.56-68, January, 2008[doi>10.1016/j.inffus.2006.11.002]
Ueda, N. and Nakano, R. 1996. Generalization error of ensemble estimators. In Proceedings of the IEEE Conference on Neural Networks. Vol. 1. 90--95.
Vafaie, H. and Jong, K. D. 1993. Robust feature selection algorithms. In Proceedings of the IEEE Conference on Tools for Artificial Intelligence. 356--363.
Antanas Verikas , Arunas Lipnickas , Kerstin Malmqvist , Marija Bacauskiene , Adas Gelzinis, Soft combination of neural classifiers: a comparative study, Pattern Recognition Letters, v.20 n.4, p.429-444, April 1999[doi>10.1016/S0167-8655(99)00012-4]
Vlachos, P. 2005. Statlib: Datasets archive. http://lib.stat.cmu.edu/datasets/.
Haixun Wang , Wei Fan , Philip S. Yu , Jiawei Han, Mining concept-drifting data streams using ensemble classifiers, Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, August 24-27, 2003, Washington, D.C.[doi>10.1145/956750.956778]
Geoffrey I. Webb , Zijian Zheng, Multistrategy Ensemble Learning: Reducing Error by Combining Ensemble Learning Techniques, IEEE Transactions on Knowledge and Data Engineering, v.16 n.8, p.980-991, August 2004[doi>10.1109/TKDE.2004.29]
Elaine J. Weyuker , Thomas J. Ostrand , Robert M. Bell, Comparing the effectiveness of several modeling methods for fault prediction, Empirical Software Engineering, v.15 n.3, p.277-295, June      2010[doi>10.1007/s10664-009-9111-2]
Wichard, J., Merkwirth, C., and Ogorzalek, M. 2003. Building ensembles with heterogeneous models. In Course of the International School on Neural Nets.
D. Randall Wilson , Tony R. Martinez, Improved heterogeneous distance functions, Journal of Artificial Intelligence Research, v.6 n.1, p.1-34, January 1997
Ian H. Witten , Eibe Frank , Mark A. Hall, Data Mining: Practical Machine Learning Tools and Techniques, Morgan Kaufmann Publishers Inc., San Francisco, CA, 2011
David H. Wolpert, Original Contribution: Stacked generalization, Neural Networks, v.5 n.2, p.241-259, 1992[doi>10.1016/S0893-6080(05)80023-1]
Kevin Woods , W. Philip Kegelmeyer, Jr. , Kevin Bowyer, Combination of Multiple Classifiers Using Local Accuracy Estimates, IEEE Transactions on Pattern Analysis and Machine Intelligence, v.19 n.4, p.405-410, April 1997[doi>10.1109/34.588027]
Jihoon Yang , Vasant G. Honavar, Feature Subset Selection Using a Genetic Algorithm, IEEE Intelligent Systems, v.13 n.2, p.44-49, March 1998[doi>10.1109/5254.671091]
Dragomir Yankov , Dennis DeCoste , Eamonn Keogh, Ensembles of nearest neighbor forecasts, Proceedings of the 17th European conference on Machine Learning, September 18-22, 2006, Berlin, Germany[doi>10.1007/11871842_51]
Yao, X., Fischer, M., and Brown, G. 2001. Neural network ensembles and their application to traffic flow prediction in telecommunications networks. Neural Netw. 1, 693--698.
Yang Yu , Zhi-Hua Zhou , Kai Ming Ting, Cocktail Ensemble for Regression, Proceedings of the 2007 Seventh IEEE International Conference on Data Mining, p.721-726, October 28-31, 2007[doi>10.1109/ICDM.2007.60]
Zemel, R. S. and Pitassi, T. 2001. Advances in NeuralInformation Processing Systems. Vol. 13. MIT Press, Chapter A gradient-based boosting algorithm for regression problems, 696--702.
Gabriele Zenobi , Padraig Cunningham, Using Diversity in Preparing Ensembles of Classifiers Based on Different Feature Subsets to Minimize Generalization Error, Proceedings of the 12th European Conference on Machine Learning, p.576-587, September 05-07, 2001
Zhang, C.-X., Zhang, J.-S., and Wang, G.-W. 2008. An empirical study of using rotation forest to improve regressors. Appl. Math. Comput. 195, 2, 618--629.
Zhang, J., Zou, Y., and Fan, Y. 2009. Embedded neural network to model-based permanent magnet synchronous motor diagnostics. In Proceedings of the Power Electronics and Motion Control Conference. 1813--1817.
Qiang-Li Zhao , Yan-Huang Jiang , Ming Xu, A fast ensemble pruning algorithm based on pattern mining process, Data Mining and Knowledge Discovery, v.19 n.2, p.277-292, October   2009[doi>10.1007/s10618-009-0138-1]
Zhi-Hua Zhou , Wei Tang, Selective ensemble of decision trees, Proceedings of the 9th international conference on Rough sets, fuzzy sets, data mining, and granular computing, May 26-29, 2003, Chongqing, China
Zhi-Hua Zhou , Jianxin Wu , Wei Tang, Ensembling neural networks: many could be better than all, Artificial Intelligence, v.137 n.1-2, p.239-263, May 2002[doi>10.1016/S0004-3702(02)00190-X]
