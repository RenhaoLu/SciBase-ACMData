In 1973 Dijkstra introduced to computer science the notion of self-stabilization in the context of distributed systems. He defined a system asself-stabilizingwhen “regardless of its initial state, it is guaranteed to arrive at a legitimate state in a finite number of steps.” A system which is not self-stabilizing may stay in an illegitimate state forever. Dijkstra's notion of self-stabilization, which originally had a very narrow scope of application, is proving to encompass a formal and unified approach to fault tolerance under a model of transient failures for distributed systems. In this paper we define self-stabilization, examine its significance in the context of fault tolerance, define the important research themes that have arisen from it, and discuss the relevant results. In addition to the issues arising from Dijkstra's original presentation as well as several related issues, we discuss methodologies for designing self-stabilizing systems, the role of compilers with respect to self-stabilization, and some of the factors that prevent self-stabilization.