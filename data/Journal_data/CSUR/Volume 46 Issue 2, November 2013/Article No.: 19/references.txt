Absar, R. and Guastavino, C. 2008. Usability of non-speech sounds in user interfaces. In Proceedings of the International Conference on Auditory Display.
Ando, B. 2008. A smart multisensor approach to assist blind people in specific urban navigation tasks. IEEE Trans. Neural Syst. Rehabil. Eng. 16, 6, 592--594.
Ando, B. and Graziani, S. 2009. Multisensor strategies to assist blind people: A clear-path indicator. IEEE Trans. Instr. Measurement 58, 8, 2488--2494.
Ballas, J. A. 1993. Common factors in the identification of an assortment of brief everyday sounds. J. Exp. Psychol. Human 19, 2, 250--267.
Barrass, S. 1996a. TaDa&excl; Demonstrations of auditory information design. In Proceedings of the International Conference on Auditory Display, 6 pages.
Barrass, S. 1996b. EarBenders: Using stories about listening to design auditory interfaces. In Proceedings of the 1st Asia-Pacific Conference on Human-Computer Interaction (APCHI’96). 525--538.
Stephen Barrass , Phil Robertson, Auditory information design, The Australian National University (Australia), 1998
Basta, D., Singbartl, F., Todt, I., Clarke, A., and Ernst, A. 2008. Vestibular rehabilitation by auditory feedback in otolith disorders. Gait Posture 28, 3, 397--404.
Begault, D. R., Wenzel, E., and Anderson, M. 2001. Direct comparison of the impact of head tracking reverberation, and individualized head-related transfer functions on the spatial perception of a virtual speech source. J. Audio Eng. Soc. 49, 10, 904--917.
Bertin, J. 1981. Graphics and Graphic Information Processing. Walter de Gruyter and Co.
Marco Bezzi , Giovanni de Poli , Davide Rocchesso, Sound Authoring Tools for Future Multimedia Systems, Proceedings of the 1999 IEEE International Conference on Multimedia Computing and Systems, p.512, June 07-11, 1999[doi>10.1109/MMCS.1999.778529]
Meera M. Blattner , Denise A. Sumikawa , Robert M. Greenberg, Earcons and icons: their structure and common design principles, Human-Computer Interaction, v.4 n.1, p.11-44, March 1989[doi>10.1207/s15327051hci0401_1]
Blauert, J. 1983. Spatial Hearing. MIT Press, Cambridge, MA.
Bonebright, T. and Nees, M. 2007. Memory for auditory icons and earcons with localization cues. In Proceedings of the International Conference on Auditory Display. 419--422.
Bourbakis, N. 2008. Sensing surrounding 3-D space for navigation of the blind. IEEE Eng. Med. Biol. Mag. 27, 1, 49--55.
Bovermann, T., Hermann, T., and Ritter, H. 2006. Tangible data scanning sonification model. In Proceedings of the International Conference on Auditory Display.
Bovermann, T. 2009. Tangible auditory interfaces: Combining auditory displays and tangible interfaces. Ph.D. thesis. University of Bielefeld.
Boyd, L. H., Boyd, W. L., and Vanderheiden, G. C. 1990. The graphical user interface: Crisis, danger and opportunity. J. Vis. Impair. Blind. 48, 10, 496--502.
Brewster, S. 1994. Providing a structured method for integrating non-speech audio into human-computer interfaces. Ph.D. thesis. University of York.
Stephen Brewster , Peter C. Wright , Alistair D. N. Edwards, Parallel earcons: reducing the length of audio messages, International Journal of Human-Computer Studies, v.43 n.2, p.153-175, Aug. 1995[doi>10.1006/ijhc.1995.1039]
Stephen A. Brewster, Using nonspeech sounds to provide navigation cues, ACM Transactions on Computer-Human Interaction (TOCHI), v.5 n.3, p.224-259, Sept. 1998[doi>10.1145/292834.292839]
Brock, D., Ballas, J. A., and McFarlane, D. 2005. Encoding urgency in legacy audio alerting systems. In Proceedings of the 11th International Conference on Auditory Display. Limerick, Ireland.
Bussemakers, M. P. and de Haan, A. 2000. When it sounds like a duck and it looks like a dog: Auditory icons vs. earcons in multimedia environments. In Proceedings of the International Conference on Auditory Display. 184--189.
Capelle, C., Trullemans, C., Arno, P., and Veraart, C. 1998. A real-time experimental prototype for enhancement of vision rehabilitation using auditory system. IEEE Trans. Biomed. Eng. 45, 10, 1279--1293.
Sylvain Cardin , Daniel Thalmann , Frédéric Vexo, A wearable system for mobility improvement of visually impaired people, The Visual Computer: International Journal of Computer Graphics, v.23 n.2, p.109-118, January 2007[doi>10.1007/s00371-006-0032-4]
Carello, C., Anderson, K. L., and Kunkler-Peck, A. J. 1998. Perception of object length by sound. Psych. Sci. 9, 3, 211--214.
Cheng, C. I. and Wakefield, G. H. 2001. Introduction to head-related transfer functions (HRTFs): Representations of HRTFs in time, frequency, and space. J. Audio Eng. Soc. 49, 4, 231--249.
Crispien, K. and Petrie, H. 1993. Providing access to GUI's using multimedia system—based on spatial audio representation. J. Audio Eng. Soc. 95th Convention Preprint.
Csapó, A. and Baranyi, P. 2011. Perceptual interpolation and open-ended exploration of auditory icons and earcons. In Proceedings of the International Conference on Auditory Display.
Csapó, A. and Baranyi, P. 2012. The spiral discovery method: An interpretable tuning model for CogInfoCom channels. JACIII 16, 2, 358--367.
Dimitrios Dakopoulos , Nikolaos G. Bourbakis, Wearable obstacle avoidance electronic travel aids for blind: a survey, IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews, v.40 n.1, p.25-35, January 2010[doi>10.1109/TSMCC.2009.2021255]
Debnath, N., Hailani, Z. A., Jamaludin, S., and Aljunid, S. A. K. 2001. An electronically guided walking stick for the blind. In Proceedings of the 23rd Annual EMBS International Conference. 1377--1379.
Dingler, T., Lindsay, J., and Walker, B. N. 2008. Learnability of sound cues for environmental features: Auditory icons, earcons, spearcons, and speech. In Proceedings of the International Conference on Auditory Display.
Dobrucki, A., Plaskota, P., Pruchnicki, P., Pec, M., Bujacz, M., and Strumillo, P. 2010. Measurement system for personalized head-related transfer functions and its verification by virtual source localization trials with visually impaired and sighted individuals. J. Audio Eng. Soc. 58, 9, 724--738.
Dozza, M., Chiari, L., and Horak, F. B. 2004. A portable audio-biofeedback system to improve postural control. In Proceedings of the IEEE Annual International Conference of the Engineering in Medicine and Biology Society. 4799--4802.
Maria Ebling, Virtual Senses, IEEE Pervasive Computing, v.8 n.4, p.4-5, October 2009[doi>10.1109/MPRV.2009.84]
Edworthy, J. and Hards, R. 1999. Learning auditory warnings: The effects of sound type, verbal labelling and imagery on the identification of alarm sounds. Int. J. Ind. Ergonom. 24, 603--618.
Edworthy, J., Loxley, S., and Dennis, I. 1991. Improving auditory warning design: Relationship between warning sound parameters and perceived urgency. Hum. Factors 33, 2, 205--231.
Fagerlonn, J. and Alm, H. 2010. Auditory signs to support traffic awareness. IET Intell. Transp. Syst. 4, 4, 262--269.
Fernstrom, M. and Brazil, E. 2004. Human-computer interaction design based on interactive sonification—hearing actions or instruments/agents. In Proceedings of the International Workshop on Interactive Sonification.
Fish, R. M. 1976. An audio display for the blind. IEEE Trans. Biomed. Eng. 23, 2, 144--154.
Christopher Frauenberger , Tony Stockman, Auditory display design-An investigation of a design pattern approach, International Journal of Human-Computer Studies, v.67 n.11, p.907-922, November, 2009[doi>10.1016/j.ijhcs.2009.05.008]
Frohlich, P. and Hammer, F. 2004. Expressive text-to-speech: A user-centred approach to sound design in voice-enabled mobile applications. In Proceedings of the 2nd Symposium on Sound Design. 4 pages.
William W. Gaver, Auditory icons: using sound in computer interfaces, Human-Computer Interaction, v.2 n.2, p.167-177, June 1986[doi>10.1207/s15327051hci0202_3]
William W. Gaver , Donald A. Norman, Everyday listening and auditory icons, University of California, San Diego, 1988
William W. Gaver, The SonicFinder: an interface that uses auditory icons, Human-Computer Interaction, v.4 n.1, p.67-94, March 1989[doi>10.1207/s15327051hci0401_3]
William W. Gaver, Synthesizing auditory icons, Proceedings of the INTERCHI '93 conference on Human factors in computing systems, p.228-235, May 1993, Amsterdam, The Netherlands
William W. Gaver, Sound support for collaboration, Proceedings of the second conference on European Conference on Computer-Supported Cooperative Work, p.293-308, September 25-27, 1991, Amsterdam, The Netherlands
Gaver, W. W. 1997. Auditory interfaces. Hum.-Comput. Interact. 4, 67--94.
Ghez, C., Rikakis, T., du Bois, R. L., and Cook, P. R. 2000. An auditory display system for aiding interjoint coordination. In Proceedings of the International Conference on Auditory Display.
Godbout, A. and Boyd, J. E. 2010. Corrective sonic feedback for speed skating: A case study. In Proceedings of the International Conference on Auditory Display. 23--30.
González, J., Yu, W., and Arieta, A. H. 2010. Multichannel audio biofeedback for dynamical coupling between prosthetic hands and their users. Ind. Robot 37, 2, 148--156.
Graham, R. 1999. Use of auditory icons as emergency warnings: Evaluation within a vehicle collision avoidance application. Ergonomics 42, 9, 1233--1248.
GW Micro. Window-Eyes. http://www.gwmicro.com/Window-Eyes/.
Gygi, B. 2004. Studying environmental sounds the Watson way. J. Acoustical Soc. Am. 115, 5, 2574.
Brian Gygi , Valeriy Shafiro, From signal to substance and back: insights from environmental sound research to auditory display design, Proceedings of the 6th international conference on Auditory Display, May 18-22, 2009, Copenhagen, Denmark[doi>10.1007/978-3-642-12439-6_16]
Gygi, B., Kidd, G. R., and Watson, C. S. 2004. Spectral-temporal factors in the identification of environmental sounds. J. Acoustical Soc. Am. 115, 3, 1252--1265.
Haas, E. C. and Edworthy, J. 1999. The perceived urgency and detection time of multitone auditory signals. In N. A. Stanton and J. Edworthy, Eds., Human Factors in Auditory Warnings. Gower Technical Press, 129--149.
Harness, S. J., Pugh, K., Sherkat, N., and Whitrow, R. J. 1993. Enabling the use of Windows environment by the blind and partially sighted. In Proceedings of the IEEE Colloquium on Information Access for People with Disability. 1--3.
Marti A. Hearst, Dissonance on Audio Interfaces, IEEE Expert: Intelligent Systems and Their Applications, v.12 n.5, p.10-16, September 1997[doi>10.1109/64.621221]
Heller, L. M. and Wolf, L. 2002. When sound effects are better than the real thing. J. Acoustical Soc. Am. 111, 5, 2339.
Hellier, E. J., Edworthy, J., and Dennis, I. 1993. Improving auditory warning design: Quantifying and predicting the effects of different warning parameters on perceived urgency. Hum. Factors 35, 4, 693--706.
Hermann, T. 2002. Sonification for exploratory data analysis. Ph.D. thesis. Bielefeld University.
Thomas Hermann , Andy Hunt, Guest Editors' Introduction: An Introduction to Interactive Sonification, IEEE MultiMedia, v.12 n.2, p.20-24, April 2005[doi>10.1109/MMUL.2005.26]
Hermann, T. and Ritter, H. 1999. Listen to your data: Model based sonification for data analysis. In G. E. Lasker, Ed., Advances in Intelligent Computing and Multimedia Systems. 189--194.
Hermann, T. and Zehe, S. 2011. Sonified aerobics—interactive sonification of coordinated body movements. In Proceedings of the International Conference on Auditory Display.
Hermann, T., Hunt, A., and Neuhoff, J. G. (Eds.). 2011. The Sonification Handbook. Logos Publishing House, Berlin.
Marion Hersh , Michael A. Johnson, Assistive Technology for Visually Impaired and Blind People, Springer Publishing Company, Incorporated, 2008
Hunt, A. and Hermann, T. 2004. The importance of interaction in sonification. In Proceedings of the International Conference on Auditory Display.
Jameson, B. and Manduchi, R. 2010. Watch your head: A wearable collision warning system for the blind. In Proceedings of IEEE Sensors. 1922--1927.
Jeon, M. and Walker, B. 2009. Spindex: Accelerated initial speech sounds improve navigation performance in auditory menus. Proc. Hum. Fact. Ergon. Soc. Annu. Meet. 53, 17, 1081--1085.
Myounghoon Jeon , Bruce N. Walker, Spindex (Speech Index) Improves Auditory Menu Acceptance and Navigation Performance, ACM Transactions on Accessible Computing (TACCESS), v.3 n.3, p.1-26, April 2011[doi>10.1145/1952383.1952385]
Antti Jylhä , Cumhur Erkut, Auditory feedback in an interactive rhythmic tutoring system, Proceedings of the 6th Audio Mostly Conference: A Conference on Interaction with Sound, p.109-115, September 07-09, 2011, Coimbra, Portugal[doi>10.1145/2095667.2095683]
Kahol, K., Tripathi, P., Panchanathan, S., and Goldberg, M. 2004. Formalizing cognitive and motor strategy of haptic exploratory movements of individuals who are blind. In Proceedings of the 3rd IEEE International Workshop on Haptic, Audio and Visual Environments and Their Applications. 25--30.
Kay, L. 1973. The design and evaluation of a sensory aid to enhance spatial perception of the blind. Electrical Eng. Report 21, Department of Electrical Engineering, University of Canterbury, New Zealand.
Kay, L. 1984. Electronic aids for blind persons: An interdisciplinary subject. IEEE Proc. A, Phys. Sci. Meas. Instrum. Manage. Educ., Rev. 131, 7, 559--576.
Kim, J. K. and Zatorre, R. J. 2008. Generalized learning of visual-to-auditory substitution in sighted individuals. Brain Res. 1242, 263--275.
Gregory Kramer, Auditory Display: Sonification, Audification, and Auditory Interfaces, Perseus Publishing, 1993
Kummer, N., Kadish, D., Dulic, A., and Najjaran, H. 2012. The empathy machine. In Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics (SMC’12). 2265--2271.
Kunkler-Peck, A. J. and Turvey, M. T. 2000. Hearing shape. J. Exp. Psychol. Hum. Percept. Perform. 26, 1, 279--294.
Lahav, O., Schloerb, D. W., Kumar, S., and Srinivasan, M. A. 2008. BlindAid: A learning environment for enabling people who are blind to explore and navigate through unknown real spaces. In Proceedings of the Conference on Virtual Rehabilitation. Vancouver, Canada, 193--197.
Legroux, S., Manzolli, J., and Verschure, P. 2007. Interactive sonification of the spatial behavior of human and synthetic characters in a mixed-reality environment. In Proceedings of the 10th Annual International Workshop on Presence. 27--34.
Grégory Leplâtre , Stephen A. Brewster, An investigation of using music to provide navigation cues, Proceedings of the 1998 international conference on Auditory Display, p.19-19, November 01-04, 1998, UK
Liard, C. and Beghdadi, A. 2001. An audiodisplay tool for visually impaired people: The sound screen system. In Proceedings of the 6th International Symposium on Signal Processing and Its Applications. 198--201.
Loomis, J. M., Marston, J. R., Golledge, R. G., and Klatzky, R. L. 2005. Personal guidance system for people with visual impairment: A comparison of spatial displays for route guidance. J. Vis. Impair. Blind. 99, 219--232.
Lopez, M. J. and Pauletto, S. 2009. The design of an audio film for the visually impaired. In Proceedings of the International Conference on Auditory Display. 210--216.
López, J. J., Cobos, M., and Pueo, B. 2010. Elevation in wave-field synthesis using HRTF cues. Acta Acust. United Ac. 96, 2, 340--350.
Massimino, M. 1992. Sensory substitution for force feedback in space teleoperation. Ph.D. thesis. MIT Department of Mechanical Engineering, Cambridge, MA.
Massimino, M. 1995. Improved force perception through sensory substitution. Control Eng. Pract. 3, 2, 215--222.
McGee-Lennon, M. R. and Brewster, S. 2011. Reminders that make sense: Designing multimodal notifications for the home. In Proceedings of the 5th International Conference on Pervasive Computing Technologies for Healthcare. 495--501.
Marilyn McGee-Lennon , Maria Wolters , Ross McLachlan , Stephen Brewster , Cordelia Hall, Name that tune: musicons as reminders in the home, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, May 07-12, 2011, Vancouver, BC, Canada[doi>10.1145/1978942.1979357]
David K. McGookin , Stephen A. Brewster, Understanding concurrent earcons: Applying auditory scene analysis principles to concurrent earcon recognition, ACM Transactions on Applied Perception (TAP), v.1 n.2, p.130-155, October 2004[doi>10.1145/1024083.1024087]
McKiel, F. 1992. Audio-enabled graphical user interface for the blind or visually impaired. In Proceedings of the Johns Hopkins National Search for Computing Applications to Assist Persons with Disabilities. 185--187.
McLachlan, R., McGee-Lennon, M., and Brewster, S. 2012. The sound of musicons: Investigating the design of musically derived audio cues. In Proceedings of the International Conference on Auditory Display. 148--155.
Meijer, P. 1992. An experimental system for auditory image representations. IEEE Trans. Biomed. Eng. 39, 2, 112--121.
Moller, H. 1992. Fundamentals of binaural technology. Appl. Acoust. 36, 171--218.
Moller, H., Sorensen, M. F., Hammershoi, D., and Jensen, C. B. 1995. Head-related transfer functions of human subjects. J. Audio Eng. Soc. 43, 5, 300--321.
Morrissette, D. L., Goodrich, G. L., and Hennessey, J. J. 1981. A follow-up study of the Mowat Sensor's applications, frequency of use, and maintenance reliability. J. Vis. Impair. Blind. 75, 211--247.
Murphy, E. F. 1971. The VA-Bionic laser cane for the blind. In National Research Council (Ed.), Evaluation of Sensory Aids for the Visually Handicapped. National Academy of Sciences.
Mustonen, M.-S. 2008. A review-based conceptual analysis of auditory signs and their design. In Proceedings of the International Conference on Auditory Display.
Elizabeth D. Mynatt, Transforming graphical interfaces into auditory interfaces for blind users, Human-Computer Interaction, v.12 n.1, p.7-45, March 1997[doi>10.1207/s15327051hci1201&2_2]
Nees, M. A. and Walker, B. N. 2007. Listener, task, and auditory graph: Toward a conceptual model of auditory graph comprehension. In Proceedings of the International Conference on Auditory Display. 266--273.
Németh, G., Olaszy, G., and Csapó, T. G. 2011. Spemoticons: Text-to-speech based emotional auditory cues. International Conference on Auditory Display (keynote lecture).
James F. O'Brien , Chen Shen , Christine M. Gatchalian, Synthesizing sounds from rigid-body simulations, Proceedings of the 2002 ACM SIGGRAPH/Eurographics symposium on Computer animation, July 21-22, 2002, San Antonio, Texas[doi>10.1145/545261.545290]
Palladino, D. K. and Walker, B. N. 2007. Learning rates for auditory menus enhanced with spearcons versus earcons. In Proceedings of the International Conference on Auditory Display. 6 pages.
Parseihian, G. and Katz, B. F. G. 2012. Morphocons: A new sonification concept based on morphological earcons. J. Audio Eng. Soc. 60, 6, 409--418.
Patterson, R. D. 1982. Guidelines for auditory warning systems on civil aircraft. CAA paper 82017. London Civil Aviation Authority.
Patterson, R. D. 1989. Guidelines for the design of auditory warning sounds. Proc. Inst. Acoust. 11, 5, 17--24.
Patterson, R. D. and Mayfield, T. F. 1990. Auditory warning sounds in the work environment. Phil. Trans. R. Soc. London 327, 1241, 485--492.
Helen Petrie , Sarah Morley, The use of non-speech sounds in non-visual interfaces to the MS-Windows GUI for blind computer users, Proceedings of the 1998 international conference on Auditory Display, p.22-22, November 01-04, 1998, UK
Pressey, N. 1977. Mowat sensor. Focus 3, 35--39.
Davide Rocchesso , Roberto Bresin , Mikael Fernström, Sounding Objects, IEEE MultiMedia, v.10 n.2, p.42-52, March 2003[doi>10.1109/MMUL.2003.1195160]
Schafer, R. M. 1977. The Tuning of the World. McClelland and Stewart Limited.
Schaeffer, P. 1966. Traite des objects musicaux. Editions du Seuil.
Schaffert, N., Gehret, R., and Mattes, K. 2012. Modeling the rowing stroke cycle acoustically. J. Audio Eng. Soc. 60, 7/8, 551--560.
Nina Schaffert , Klaus Mattes , Alfred O. Effenberg, A sound design for acoustic feedback in elite sports, Proceedings of the 6th international conference on Auditory Display, May 18-22, 2009, Copenhagen, Denmark[doi>10.1007/978-3-642-12439-6_8]
Schaffert, N., Mattes, K., and Effenberg, A. O. 2011. An investigation of online acoustic information for elite rowers in on-water training conditions. J. Hum. Sport Exerc. 6, 2, 392--405.
Cynthia A. Sikora , Linda Roberts , La Tondra Murray, Musical vs. real world feedback signals, Conference Companion on Human Factors in Computing Systems, p.220-221, May 07-11, 1995, Denver, Colorado, USA[doi>10.1145/223355.223534]
Singh, D. 2010. Hybrid auditory based interaction framework for driver assistance system. J. Comput. Sci. 6, 12, 1499--1504.
Kees van den Doel , Paul G. Kry , Dinesh K. Pai, FoleyAutomatic: physically-based sound effects for interactive simulation and animation, Proceedings of the 28th annual conference on Computer graphics and interactive techniques, p.537-544, August 2001[doi>10.1145/383259.383322]
Ventura, L. C. L. and Fernandes, P. R. 2011. Remote guide for guiding the visually Impaired. In Proceedings of the 2011 ISSNIP Biosignals and Biorobotics Conference (BRC’11). 1--5.
Walker, B. N., Nance, A., and Lindsay, J. 2006. Spearcons: Speech-based earcons improve navigation performance in auditory menus. In Proceedings of the International Conference on Auditory Display. 63--68.
Walker, B. N. and Lindsay, J. 2006. Navigation performance with a virtual auditory display: Effects of beacon sound, capture radius, and practice. Hum. Factors 48, 2, 265--278.
Elizabeth M. Wenzel, Localization in virtual acoustic displays, Presence: Teleoperators and Virtual Environments, v.1 n.1, p.80-107, Winter 1992
Wenzel, E. M., Arruda, M., Kistler, D. J., and Wightman F. L. 1994. Localization using nonindividualized head-related transfer functions. J. Acoustical Soc. Am. 94, 1, 111--123.
Wersényi, G. 2003. Localization in a HRTF-based minimum audible angle listening test on a 2D sound screen for GUIB applications. Audio Engineering Society Convention Preprint Paper, No. 5902, New York.
Wersényi, G. 2007a. Localization in a HRTF-based minimum-audible-angle listening test for GUIB applications. EJTA 1, 1--16. Available at http://www.ejta.org.
Wersényi, G. 2007b. Localization in a HRTF-based virtual audio synthesis using additional high-pass and low-pass filtering of sound sources. J. Acoust. Sci. Technol. Jpn. 28, 4, 244--250.
Wersényi, G. 2008. Evaluation of user habits for creating auditory representations of different software applications for blind persons. In Proceedings of the International Conference on Auditory Display.
Wersényi, G. 2009a. Evaluation of auditory representations for selected applications of a graphical user interface. In Proceedings of the International Conference on Auditory Display. 41--48.
György Wersényi, Effect of emulated head-tracking for reducing localization errors in virtual audio simulation, IEEE Transactions on Audio, Speech, and Language Processing, v.17 n.2, p.247-252, February 2009[doi>10.1109/TASL.2008.2006720]
György Wersényi, Auditory representations of a graphical user interface for a better human-computer interaction, Proceedings of the 6th international conference on Auditory Display, May 18-22, 2009, Copenhagen, Denmark[doi>10.1007/978-3-642-12439-6_5]
Wersényi, G. 2012. Virtual localization by blind persons. J. Audio Eng. Soc. 60, 7/8, 568--579.
Jeff Wilson , Bruce N. Walker , Jeffrey Lindsay , Craig Cambias , Frank Dellaert, SWAN: System for Wearable Audio Navigation, Proceedings of the 2007 11th IEEE International Symposium on Wearable Computers, p.1-8, October 11-13, 2007[doi>10.1109/ISWC.2007.4373786]
W3: http://www.w3.org/.
