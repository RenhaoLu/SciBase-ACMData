S. Afzal and P. Robinson. 2011. Natural affect data: Collection and annotation. In New Perspectives on Affect and Learning Technologies, R. Calvo and S. D'Mello (Eds.) Springer, New York, NY, 44--70.
Jeremy N. Bailenson , Emmanuel D. Pontikakis , Iris B. Mauss , James J. Gross , Maria E. Jabon , Cendri A. C. Hutcherson , Clifford Nass , Oliver John, Real-time classification of evoked emotions using facial feature tracking and physiological responses, International Journal of Human-Computer Studies, v.66 n.5, p.303-317, May, 2008[doi>10.1016/j.ijhcs.2007.10.011]
T. Baltrušaitis, N. Banda, and P. Robinson. 2013. Dimensional affect recognition using continuous conditional random fields. In Proceedings of the International Conference on Multimedia and Expo (Workshop on Affective Analysis in Multimedia).
N. Banda and P. Robinson. 2011. Noise analysis in audio-visual emotion recognition. In Proceedings of the 11th International Conference on Multimodal Interaction (ICMI).
L. Barrett. 2006. Are emotions natural kinds&quest; Perspect. Psychol. Sci. 1, 28--58.
L. Barrett, B. Mesquita, K. Ochsner, and J. Gross. 2007. The experience of emotion. Ann. Rev. Psychol. 58, 373--403.
M. Borenstein, L. V. Hedges, J. P. T. Higgins, and H. R. Rothstein. 2009. Introduction to Meta-Analysis. John Wiley & Sons, Inc., Hoboken, NJ.
Scott Brave , Clifford Nass, Emotion in human-computer interaction, The human-computer interaction handbook: fundamentals, evolving technologies and emerging applications, L. Erlbaum Associates Inc., Hillsdale, NJ, 2002
Carlos Busso , Zhigang Deng , Serdar Yildirim , Murtaza Bulut , Chul Min Lee , Abe Kazemzadeh , Sungbok Lee , Ulrich Neumann , Shrikanth Narayanan, Analysis of emotion recognition using facial expressions, speech and multimodal information, Proceedings of the 6th international conference on Multimodal interfaces, October 13-15, 2004, State College, PA, USA[doi>10.1145/1027933.1027968]
R. Calvo, S. K. D'Mello, J. Gratch, and A. Kappas. 2014. The Oxford Handbook of Affective Computing. Oxford University Press, New York, NY.
Rafael A. Calvo , Sidney D'Mello, Affect Detection: An Interdisciplinary Review of Models, Methods, and Their Applications, IEEE Transactions on Affective Computing, v.1 n.1, p.18-37, January 2010[doi>10.1109/T-AFFC.2010.1]
George Caridakis , Lori Malatesta , Loic Kessous , Noam Amir , Amaryllis Raouzaiou , Kostas Karpouzis, Modeling naturalistic affective states via facial and vocal expressions recognition, Proceedings of the 8th international conference on Multimodal interfaces, November 02-04, 2006, Banff, Alberta, Canada[doi>10.1145/1180995.1181029]
Ginevra Castellano , Loic Kessous , George Caridakis, Emotion Recognition through Multiple Modalities: Face, Body Gesture, Speech, Affect and Emotion in Human-Computer Interaction: From Theory to Applications, Springer-Verlag, Berlin, Heidelberg, 2008[doi>10.1007/978-3-540-85099-1_8]
Ginevra Castellano , André Pereira , Iolanda Leite , Ana Paiva , Peter W. McOwan, Detecting user engagement with a robot companion using task and social interaction-based features, Proceedings of the 2009 international conference on Multimodal interfaces, November 02-04, 2009, Cambridge, Massachusetts, USA[doi>10.1145/1647314.1647336]
Guillaume Chanel , Cyril Rebetez , Mireille Bétrancourt , Thierry Pun, Emotion Assessment From Physiological Signals for Adaptation of Game Difficulty, IEEE Transactions on Systems, Man, and Cybernetics, Part A: Systems and Humans, v.41 n.6, p.1052-1063, November 2011[doi>10.1109/TSMCA.2011.2116000]
C.-Y. Chen, Y.-K. Huang, and P. Cook. 2005. Visual/Acoustic emotion recognition. In Proceedings of the IEEE International Conference on Multimedia and Expo. IEEE, Washington, DC, 1468--1471.
G. Chetty and M. Wagner. 2008. A multilevel fusion approach for audiovisual emotion recognition. In Proceedings of the International Conference on Auditory-Visual Speech Processing, 115--120.
Z.-J. Chuang and C.-H. Wu. 2004. Multi-modal emotion recognition from speech and text. Int. J. Comput. Ling. Chin. Lang. Process. 9, 1--18.
J. A. Coan. 2010. Emergent ghosts of the emotion machine. Emotion Rev. 2, 274--285.
J. Cohen. 1992. A power primer. Psychol. Bull. 112, 155--159.
Cristina Conati , Heather Maclaren, Empirically building and evaluating a probabilistic model of user affect, User Modeling and User-Adapted Interaction, v.19 n.3, p.267-303, August    2009[doi>10.1007/s11257-009-9062-8]
Cristina Conati , Stacy Marsella , Ana Paiva, Affective interactions: the computer in the affective loop, Proceedings of the 10th international conference on Intelligent user interfaces, January 10-13, 2005, San Diego, California, USA[doi>10.1145/1040830.1040838]
Roddy Cowie , Ellen Douglas-Cowie , Cate Cox, 2005 Special Issue: Beyond emotion archetypes: Databases for emotion modelling using neural networks, Neural Networks, v.18 n.4, p.371-388, May 2005[doi>10.1016/j.neunet.2005.03.002]
R. Cowie, E. Douglas-Cowie, N. Tsapatsoulis, G. Votsis, S. Kollias, W. Fellenz, and J. Taylor. 2001. Emotion recognition in human-computer interaction. IEEE Sig. Process. Mag. 18, 32--80.
Diego R. Cueva , Rafael A. M. Gonçalves , Fábio Cozman , Marcos R. Pereira-Barretto, Crawling to improve multimodal emotion detection, Proceedings of the 10th international conference on Artificial Intelligence: advances in Soft Computing, November 26-December 04, 2011, Puebla, Mexico[doi>10.1007/978-3-642-25330-0_30]
S. D'Mello. 2013. A selective meta-analysis on the relative incidence of discrete affective states during learning with technology. J. Educ. Psychology Psychol. 105, 1082--1099.
Sidney D'mello , Arthur Graesser, Mind and Body: Dialogue and Posture for Affect Detection in Learning Environments, Proceedings of the 2007 conference on Artificial Intelligence in Education: Building Technology Rich Learning Contexts That Work, p.161-168, June 08, 2007
Sidney K. D'Mello , Arthur Graesser, Multimodal semi-automated affect detection from conversational cues, gross body language, and facial features, User Modeling and User-Adapted Interaction, v.20 n.2, p.147-187, June      2010[doi>10.1007/s11257-010-9074-4]
Sidney D'mello , Art Graesser, AutoTutor and affective autotutor: Learning by talking with cognitively and emotionally intelligent computers that talk back, ACM Transactions on Interactive Intelligent Systems (TiiS), v.2 n.4, p.1-39, December 2012[doi>10.1145/2395123.2395128]
Sidney D'Mello , Jacqueline Kory, Consistent but modest: a meta-analysis on unimodal and multimodal affect detection accuracies from 30 studies, Proceedings of the 14th ACM international conference on Multimodal interaction, October 22-26, 2012, Santa Monica, California, USA[doi>10.1145/2388676.2388686]
S. K. D'Mello and A. C. Graesser. 2014. Confusion. In International Handbook of Emotions in Education, R. Pekrun and L. Linnenbrink-Garcia (Eds.). Routledge, New York, NY, 289--310.
S. D'Mello and A. Graesser. 2011. The half-life of cognitive-affective states during complex learning. Cognition Emotion 25, 1299--1308.
Dragoş Datcu , Léon J. M. Rothkrantz, Emotion recognition using bimodal data fusion, Proceedings of the 12th International Conference on Computer Systems and Technologies, June 16-17, 2011, Vienna, Austria[doi>10.1145/2023607.2023629]
S. Dobrišek, R. Gajšek, F. Mihelič, N. Pavešić, and V. Štruc. 2013. Towards efficient multi-modal emotion recognition. Int. J. Adv. Robotic Syst. 10, 1--10.
Ellen Douglas-Cowie , Roddy Cowie , Ian Sneddon , Cate Cox , Orla Lowry , Margaret Mcrorie , Jean-Claude Martin , Laurence Devillers , Sarkis Abrilian , Anton Batliner , Noam Amir , Kostas Karpouzis, The HUMAINE Database: Addressing the Collection and Annotation of Naturalistic and Induced Emotional Data, Proceedings of the 2nd international conference on Affective Computing and Intelligent Interaction, September 12-14, 2007, Lisbon, Portugal[doi>10.1007/978-3-540-74889-2_43]
S. Duval and R. Tweedie. 2000. Trim and fill: A simple funnel-plot--based method of testing and adjusting for publication bias in meta-analysis. Biometrics 56, 455--463.
M. Dy, I. Espinosa, P. Go, C. Mendez, and J. Cu. 2010. Multimodal emotion recognition using a spontaneous Filipino emotion database. In Proceedings of the 3rd International Conference on Human-Centric Computing. IEEE, Washington, DC, 1--5.
P. Ekman. 1992. An argument for basic emotions. Cognition Emotion 6, 169--200.
H. Elfenbein and N. Ambady. 2002. On the universality and cultural specificity of emotion recognition: A meta-analysis. Psychol. Bull. 128, 203--235.
S. Emerich, E. Lupu, and A. Apatean. 2009. Emotions recognition by speech and facial expressions analysis. In Proceedings of the 17th European Signal Processing Conference (EUSIPCO 2009). Glasgow, Scotland.
F. Eyben, M. Wöllmer, A. Graves, B. Schuller, E. Douglas-Cowie, and R. Cowie. 2010. On-line emotion recognition in a 3-D activation-valence-time continuum using acoustic and linguistic cues. J. Multimodal User Int. 3, 7--19.
F. Eyben, M. Wollmer, M. F. Valstar, H. Gunes, B. Schuller, and M. Pantic. 2011. String-based audiovisual fusion of behavioural events for the assessment of dimensional affect. In Ninth IEEE International Conference on Automatic Face and Gesture Recognition (FG 2011). IEEE, Santa Barbara, CA, 322--329.
J. Fontaine, K. Scherer, E. Roesch, and P. Ellsworth. 2007. The world of emotions is not two-dimensional. Psychol. Sci. 18, 12 (Dec. 2007) 1050--1057.
K. Forbes-Riley and D. Litman. 2004. Predicting emotion in spoken dialogue from multiple knowledge sources. In Proceedings of the 4th Meeting of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 201--208.
Kate Forbes-Riley , Diane Litman, Benefits and challenges of real-time uncertainty detection and adaptation in a spoken dialogue computer tutor, Speech Communication, v.53 n.9-10, p.1115-1136, November, 2011[doi>10.1016/j.specom.2011.02.006]
Rok Gajsek , Vitomir truc , France Mihelic, Multi-modal Emotion Recognition Using Canonical Correlations and Acoustic Features, Proceedings of the 2010 20th International Conference on Pattern Recognition, p.4133-4136, August 23-26, 2010[doi>10.1109/ICPR.2010.1005]
M. Glodek, S. Reuter, M. Schels, K. Dietmayer, and F. Schwenker. 2013. Kalman filter based classifier fusion for affective state recognition. In Proceedings of the 11th International Workshop on Multiple Classifier Systems, Z.-H. Zhou, F. Roli, and J. Kittler (Eds.). Springer, Berlin, 85--94.
Michael Glodek , Stephan Tschechne , Georg Layher , Martin Schels , Tobias Brosch , Stefan Scherer , Markus K&auml;chele , Miriam Schmidt , Heiko Neumann , G&uuml;nther Palm , Friedhelm Schwenker, Multiple classifier systems for the classificatio of audio-visual emotional states, Proceedings of the 4th international conference on Affective computing and intelligent interaction, October 09-12, 2011, Memphis, TN
Shaogang Gong , Caifeng Shan , Tao Xiang, Visual inference of human emotion and behaviour, Proceedings of the 9th international conference on Multimodal interfaces, November 12-15, 2007, Nagoya, Aichi, Japan[doi>10.1145/1322192.1322199]
A. Graesser, B. McDaniel, P. Chipman, A. Witherspoon, S. D'Mello, and B. Gholson. 2006. Detection of emotions during learning with AutoTutor. In Proceedings of the 28th Annual Conference of the Cognitive Science Society, R. Sun and N. Miyake (Eds.). Cognitive Science Society, Austin, TX, 285--290.
Hatice Gunes , Massimo Piccardi, Fusing face and body display for bi-modal emotion recognition: single frame analysis and multi-frame post integration, Proceedings of the First international conference on Affective Computing and Intelligent Interaction, October 22-24, 2005, Beijing, China[doi>10.1007/11573548_14]
Hatice Gunes , Massimo Piccardi, Automatic temporal segment detection and affect recognition from face and body display, IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, v.39 n.1, p.64-84, February 2009[doi>10.1109/TSMCB.2008.927269]
M. Han, J. Hsu, K.-T. Song, and F.-Y. Chang. 2007. A new information fusion method for SVM-based robotic audio-visual emotion recognition. In Proceedings of the IEEE International Conference on Systems, Man and Cybernetics. IEEE, Washington, DC, 2656--2661.
S. Haq and P. Jackson. 2009. Speaker-dependent audio-visual emotion recognition. In Proceedings of International Conference on Auditory-Visual Speech Processing, 53--58.
S. Haq, P. Jackson, and J. Edge. 2008. Audio-visual feature selection and reduction for emotion classification. In Proceedings of the International Conference on Auditory-Visual Speech Processing, 185--190.
S. Hoch, F. Althoff, G. McGlaun, and G. Rigoll. 2005. Bimodal fusion of emotional data in an automotive environment. In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing. IEEE, Washington, DC, 1085--1088.
S. Hommel, A. Rabie, and U. Handmann. 2013. Attention and emotion based adaption of dialog systems. In Intelligent Systems: Models and Applications, E. Pap (Ed.). Springer-Verlag, Berlin, 215--235.
M. Hoque and R. W. Picard. 2011. Acted vs. natural frustration and delight: Many people smile in natural frustration. In Proceedings of the IEEE International Conference on Automatic Face and Gesture Recognition and Workshops (FG'11). IEEE, Washington, DC, 354--359.
M. S. Hussain , Hamed Monkaresi , Rafael A. Calvo, Combining classifiers in multimodal affect detection, Proceedings of the Tenth Australasian Data Mining Conference, p.103-108, December 05-07, 2012, Sydney, Australia
C. Izard. 2010. The many meanings/aspects of emotion: Definitions, functions, activation, and regulation. Emotion Rev. 2, 363--370.
C. E. Izard. 2007. Basic emotions, natural kinds, emotion schemas, and a new paradigm. Perspect. Psychol. Sci. 2, 260--280.
Alejandro Jaimes , Nicu Sebe, Multimodal human-computer interaction: A survey, Computer Vision and Image Understanding, v.108 n.1-2, p.116-134, October, 2007[doi>10.1016/j.cviu.2006.10.019]
László A. Jeni , Jeffrey F. Cohn , Fernando De La Torre, Facing Imbalanced Data--Recommendations for the Use of Performance Metrics, Proceedings of the 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction, p.245-251, September 02-05, 2013[doi>10.1109/ACII.2013.47]
Dongmei Jiang , Yulu Cui , Xiaojing Zhang , Ping Fan , Isabel Ganzalez , Hichem Sahli, Audio visual emotion recognition based on triple-stream dynamic bayesian network models, Proceedings of the 4th international conference on Affective computing and intelligent interaction, October 09-12, 2011, Memphis, TN
J.-T. Joo, S.-W. Seo, K.-E. Ko, and K.-B. Sim. 2007. Emotion recognition method based on multimodal sensor fusion algorithm. In Proceedings of the 8th Symposium on Advanced Intelligent Systems. 200--204.
C. Kaernbach. 2011. On dimensions in emotion psychology. In Proceedings of the IEEE International Conference on Automatic Face and Gesture Recognition and Workshops. IEEE, Washington, DC, 792--796.
I. Kanluan, M. Grimm, and K. Kroschel. 2008. Audio-visual emotion recognition using an emotion space concept. In Proceedings of the 16th European Signal Processing Conference.
Ashish Kapoor , Winslow Burleson , Rosalind W. Picard, Automatic prediction of frustration, International Journal of Human-Computer Studies, v.65 n.8, p.724-736, August, 2007[doi>10.1016/j.ijhcs.2007.02.003]
Ashish Kapoor , Rosalind W. Picard, Multimodal affect recognition in learning environments, Proceedings of the 13th annual ACM international conference on Multimedia, November 06-11, 2005, Hilton, Singapore[doi>10.1145/1101149.1101300]
Kostas Karpouzis , George Caridakis , Loic Kessous , Noam Amir , Amaryllis Raouzaiou , Lori Malatesta , Stefanos Kollias, Modeling naturalistic affective states via facial, vocal, and bodily expressions recognition, Proceedings of the ICMI 2006 and IJCAI 2007 international conference on Artifical intelligence for human computing, November 03, 2006, Banff, Canada
L. Kessous, G. Castellano, and G. Caridakis. 2010. Multimodal emotion recognition in speech-based interaction using facial expression, body gesture and acoustic analysis. J. Multimodal User Int. 3, 33--48.
Z. Khalili , M. H. Moradi, Emotion recognition system using brain and peripheral signals: using correlation dimension to improve the results of EEG, Proceedings of the 2009 international joint conference on Neural Networks, p.1920-1924, June 14-19, 2009, Atlanta, Georgia, USA
J. Kim. 2007. Bimodal emotion recognition using speech and physiological changes. In Robust Speech Recognition and Understanding, M. Grimm and K. Kroschel (Eds.). I-Tech, 265--280.
J. Kim, E. André, M. Rehm, T. Vogt, and J. Wagner. 2005. Integrating information from speech and physiological signals to achieve emotional sensitivity. In Proceedings of 9th European Conference on Speech Communication and Technology. 809--812.
J. Kim and F. Lingenfelser. 2010. Ensemble approaches to parametric decision fusion for bimodal emotion recognition. In Proceedings of the International Conference on Bio-Inspired Systems and Signal Processing. BIOSTEC, 460--463.
Sander Koelstra , Christian Muhl , Mohammad Soleymani , Jong-Seok Lee , Ashkan Yazdani , Touradj Ebrahimi , Thierry Pun , Anton Nijholt , Ioannis Patras, DEAP: A Database for Emotion Analysis ;Using Physiological Signals, IEEE Transactions on Affective Computing, v.3 n.1, p.18-31, January 2012[doi>10.1109/T-AFFC.2011.15]
J. Kory and S. K. D'Mello. 2014. Affect elicitation for affective computing. In The Oxford Handbook of Affective Computing, R. Calvo, S. D'Mello, J. Gratch, and A. Kappas (Eds.). Oxford University Press, New York, NY.
Gerald Krell , Michael Glodek , Axel Panning , Ingo Siegert , Bernd Michaelis , Andreas Wendemuth , Friedhelm Schwenker, Fusion of fragmentary classifier decisions for affective state recognition, Proceedings of the First international conference on Multimodal Pattern Recognition of Social Signals in Human-Computer-Interaction, November 11-11, 2012, Tsukuba, Japan[doi>10.1007/978-3-642-37081-6_13]
M. D. Lewis. 2005. Bridging emotion theory and neurobiology through dynamic systems modeling. Behav. Brain Sci. 28, 169--245.
Jen-Chun Lin , Chung-Hsien Wu , Wen-Li Wei, Error Weighted Semi-Coupled Hidden Markov Model for Audio-Visual Emotion Recognition, IEEE Transactions on Multimedia, v.14 n.1, p.142-156, February 2012[doi>10.1109/TMM.2011.2171334]
Florian Lingenfelser , Johannes Wagner , Elisabeth André, A systematic discussion of fusion techniques for multi-modal affect recognition tasks, Proceedings of the 13th international conference on multimodal interfaces, November 14-18, 2011, Alicante, Spain[doi>10.1145/2070481.2070487]
M. W. Lipsey and D. B. Wilson. 2001. Practical meta-analysis. Sage Publications, Inc, Thousand Oaks, CA.
Diane J. Litman , Kate Forbes-Riley, Predicting student emotions in computer-human tutoring dialogues, Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, p.351-es, July 21-26, 2004, Barcelona, Spain[doi>10.3115/1218955.1219000]
D. Litman and K. Forbes-Riley. 2006a. Recognizing student emotions and attitudes on the basis of utterances in spoken tutoring dialogues with both human and computer tutors. Speech Commun. 48, 559--590.
D. J. Litman and K. Forbes-Riley. 2006b. Recognizing student emotions and attitudes on the basis of utterances in spoken tutoring dialogues with both human and computer tutors. Speech Commun. 48, 559--590.
K. Lu and Y. Jia. 2012. Audio-visual emotion recognition with boosted coupled HMM. In Proceedings of the 21st International Conference on Pattern Recognition. IEEE, Washington, DC, 1148--1151.
Muharram Mansoorizadeh , Nasrollah Moghaddam Charkari, Multimodal information fusion application to human emotion recognition from face and speech, Multimedia Tools and Applications, v.49 n.2, p.277-297, August    2010[doi>10.1007/s11042-009-0344-2]
Daniel McDuff , Rana El Kaliouby , Rosalind Picard, Crowdsourcing Facial Responses to Online Videos, IEEE Transactions on Affective Computing, v.3 n.4, p.456-468, January 2012[doi>10.1109/T-AFFC.2012.19]
Gary McKeown , Michel Valstar , Roddy Cowie , Maja Pantic , Marc Schroder, The SEMAINE Database: Annotated Multimodal Records of Emotionally Colored Conversations between a Person and a Limited Agent, IEEE Transactions on Affective Computing, v.3 n.1, p.5-17, January 2012[doi>10.1109/T-AFFC.2011.20]
Angeliki Metallinou , Sungbok Lee , Shrikanth Narayanan, Audio-Visual Emotion Recognition Using Gaussian Mixture Models for Face and Voice, Proceedings of the 2008 Tenth IEEE International Symposium on Multimedia, p.250-257, December 15-17, 2008[doi>10.1109/ISM.2008.40]
Angeliki Metallinou , Martin Wollmer , Athanasios Katsamanis , Florian Eyben , Bjorn Schuller , Shrikanth Narayanan, Context-Sensitive Learning for Enhanced Audiovisual Emotion Classification, IEEE Transactions on Affective Computing, v.3 n.2, p.184-198, April 2012[doi>10.1109/T-AFFC.2011.40]
H. Monkaresi, M. S. Hussain, and R. Calvo. 2012. Classification of affects using head movement, skin color features and physiological signals. In Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics. IEEE, Washington, DC, 2664--2669.
Mihalis A. Nicolaou , Hatice Gunes , Maja Pantic, Continuous Prediction of Spontaneous Affect from Multiple Cues and Modalities in Valence-Arousal Space, IEEE Transactions on Affective Computing, v.2 n.2, p.92-105, July 2011[doi>10.1109/T-AFFC.2011.9]
J. Ocumpaugh, R. Baker, S. Gowda, N. Heffernan, and C. Heffernan. 2014. Population validity for educational data mining: A case study in affect detection. Brit. J. Educ. Psychol. 45, 487--501.
A. Ortony, G. Clore, and A. Collins. 1988. The Cognitive Structure of Emotions. Cambridge University Press, New York.
P. Pal, A. Iyer, and R. Yantorno. 2006. Emotion detection from infant facial expressions and cries. In Proceedings. of the 2006 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, Washington, DC, 721--724.
Marco Paleari , Rachid Benmokhtar , Benoit Huet, Evidence Theory-Based Multimodal Emotion Recognition, Proceedings of the 15th International Multimedia Modeling Conference on Advances in Multimedia Modeling, p.435-446, January 07-09, 2009, Sophia-Antipolis, France[doi>10.1007/978-3-540-92892-8_44]
Bo Pang , Lillian Lee, Opinion Mining and Sentiment Analysis, Foundations and Trends in Information Retrieval, v.2 n.1-2, p.1-135, January 2008[doi>10.1561/1500000011]
M. Pantic and L. Rothkrantz. 2003. Toward an affect-sensitive multimodal human-computer interaction. Proc. IEEE 91, 1370--1390.
J. Park, G. Jang, and Y. Seo. 2012. Music-aided affective interaction between human and service robot. EURASIP J. Audio, Speech, Music Process. 2012, 1, 1--13.
Rosalind W. Picard, Affective computing, MIT Press, Cambridge, MA, 1997
Rosalind W. Picard, Affective Computing: From Laughter to IEEE, IEEE Transactions on Affective Computing, v.1 n.1, p.11-17, January 2010[doi>10.1109/T-AFFC.2010.10]
R. Plutchik. 2001. The nature of emotions. American Scientist 89, 344--350.
Ahmad Rabie , Britta Wrede , Thurid Vogt , Marc Hanheide, Evaluation and Discussion of Multi-modal Emotion Recognition, Proceedings of the 2009 Second International Conference on Computer and Electrical Engineering, p.598-602, December 28-30, 2009[doi>10.1109/ICCEE.2009.192]
Munaf Rashid , S. A. Abu-Bakar , Musa Mokji, Human emotion recognition from videos using spatio-temporal and audio features, The Visual Computer: International Journal of Computer Graphics, v.29 n.12, p.1269-1275, December  2013[doi>10.1007/s00371-012-0768-y]
G. Rigoll, R. Muller, and B. Schuller. 2005. Speech emotion recognition exploiting acoustic and linguistic information sources. In Proceedings of the 10th International Conference Speech and Computer. 61--67.
Veronica Rosas , Rada Mihalcea , Louis-Philippe Morency, Multimodal Sentiment Analysis of Spanish Online Videos, IEEE Intelligent Systems, v.28 n.3, p.38-45, May 2013[doi>10.1109/MIS.2013.9]
E. Rosenberg. 1998. Levels of analysis and the organization of affect. Rev. Gen. Psychol. 2, 247--270.
E. Rosenberg and P. Ekman. 1994. Coherence between expressive and experiential systems in emotion. Cognition Emotion 8, 201--229.
V. Rozgic, S. Ananthakrishnan, S. Saleem, R. Kumar, and R. Prasad. 2012. Ensemble of SVM trees for multimodal emotion recognition. In Proceedings of the Signal and Information Processing Association Annual Summit and Conference. IEEE, Washington, DC, 1--4.
J. Russell. 1994. Is there universal recognition of emotion from facial expression&quest; A review of the cross-cultural studies. Psychol. Bull. 115, 102--141.
J. Russell. 2003. Core affect and the psychological construction of emotion. Psychol. Rev. 110, 145--172.
J. A. Russell, J. A. Bachorowski, and J. M. Fernandez-Dols. 2003. Facial and vocal expressions of emotion. Ann. Rev. Psychol. 54, 329--349.
Arman Savran , Houwei Cao , Miraj Shah , Ani Nenkova , Ragini Verma, Combining video, audio and lexical indicators of affect in spontaneous conversation via particle filtering, Proceedings of the 14th ACM international conference on Multimodal interaction, October 22-26, 2012, Santa Monica, California, USA[doi>10.1145/2388676.2388781]
Bjorn Schuller, Recognizing Affect from Linguistic Information in 3D Continuous Space, IEEE Transactions on Affective Computing, v.2 n.4, p.192-205, October 2011[doi>10.1109/T-AFFC.2011.17]
Bjöern Schuller , Ronald Müeller , Benedikt Höernler , Anja Höethker , Hitoshi Konosu , Gerhard Rigoll, Audiovisual recognition of spontaneous interest within conversations, Proceedings of the 9th international conference on Multimodal interfaces, November 12-15, 2007, Nagoya, Aichi, Japan[doi>10.1145/1322192.1322201]
Nicu Sebe , Ira Cohen , Theo Gevers , Thomas S. Huang, Emotion Recognition Based on Joint Visual and Audio Cues, Proceedings of the 18th International Conference on Pattern Recognition, p.1136-1139, August 20-24, 2006[doi>10.1109/ICPR.2006.489]
D. Seppi, A. Batliner, B. Schuller, S. Steidl, T. Vogt, J. Wagner, L. Devillers, L. Vidrascu, N. Amir, and V. Aharonson. 2008. Patterns, prototypes, performance: Classifying emotional user states. In Proceedings of the 9th Annual Conference of the International Speech Communication Association, 601--604.
C. Shan, S. Gong, and P. McOwan. 2007. Beyond facial expressions: Learning human emotion from body gestures. In Proceedings of the British Machine Vision Conference, 1--10.
Mohammad Soleymani , Maja Pantic , Thierry Pun, Multimodal Emotion Recognition in Response to Videos, IEEE Transactions on Affective Computing, v.3 n.2, p.211-223, April 2012[doi>10.1109/T-AFFC.2011.37]
Alistair Sutcliffe, Multimedia user interface design, The human-computer interaction handbook: fundamentals, evolving technologies and emerging applications, L. Erlbaum Associates Inc., Hillsdale, NJ, 2002
S. S. Tomkins. 1962. Affect Imagery Consciousness: Volume I, The Positive Affects. Tavistock, London.
B. Tu and F. Yu. 2012. Bimodal emotion recognition based on speech signals and facial expression. In Proceedings of the 6th International Conference on Intelligent Systems and Knowledge. Springer, Berlin, 691--696.
J. Tukey and D. McLaughlin. 1963. Less vulnerable confidence and significance procedures for location based on a single sample: Trimming/Winsorization 1. Sankhyā: The Indian Journal of Statistics 25, 331--352.
Michel F. Valstar , Marc Mehu , Bihan Jiang , Maja Pantic , Klaus Scherer, Meta-Analysis of the First Facial Expression Recognition Challenge, IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, v.42 n.4, p.966-979, August 2012[doi>10.1109/TSMCB.2012.2200675]
Marjolein D. van der Zwaag , Joris H. Janssen , Joyce HDM Westerink, Directing Physiology and Mood through Music: Validation of an Affective Music Player, IEEE Transactions on Affective Computing, v.4 n.1, p.57-68, January 2013[doi>10.1109/T-AFFC.2012.28]
H. Vu, Y. Yamazaki, F. Dong, and K. Hirota. 2011. Emotion recognition based on human gesture and speech information using RT middleware. In IEEE International Conference on Fuzzy Systems. IEEE, Washington, DC, 787--791.
Johannes Wagner , Elisabeth Andre , Florian Lingenfelser , Jonghwa Kim, Exploring Fusion Methods for Multimodal Emotion Recognition with Missing Data, IEEE Transactions on Affective Computing, v.2 n.4, p.206-218, October 2011[doi>10.1109/T-AFFC.2011.12]
Steffen Walter , Stefan Scherer , Martin Schels , Michael Glodek , David Hrabal , Miriam Schmidt , Ronald Böck , Kerstin Limbrecht , Harald C. Traue , Friedhelm Schwenker, Multimodal emotion classification in naturalistic user behavior, Proceedings of the 14th international conference on Human-computer interaction: towards mobile and intelligent interaction environments, July 09-14, 2011, Orlando, FL
Shangfei Wang , Yachen Zhu , Guobing Wu , Qiang Ji, Hybrid video emotional tagging using users' EEG and video content, Multimedia Tools and Applications, v.72 n.2, p.1257-1283, September 2014[doi>10.1007/s11042-013-1450-8]
Y. Wang and L. Guan. 2005. Recognizing human emotion from audiovisual information. In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing. IEEE, Washington, DC, 1125--1128.
Y. Wang , L. Guan, Recognizing Human Emotional State From Audiovisual Signals*, IEEE Transactions on Multimedia, v.10 n.5, p.936-946, August 2008[doi>10.1109/TMM.2008.927665]
M. Wimmer, B. Schuller, D. Arsic, G. Rigoll, and B. Radig. 2008. Low-level fusion of audio and video feature for multi-modal emotion recognition. In Proceedings of the 3rd International Conference on Computer Vision Theory and Applications, 145--151.
Martin WöLlmer , Moritz Kaiser , Florian Eyben , BjöRn Schuller , Gerhard Rigoll, LSTM-Modeling of continuous emotions in an audiovisual affect recognition framework, Image and Vision Computing, v.31 n.2, p.153-163, February, 2013[doi>10.1016/j.imavis.2012.03.001]
M. Wöllmer, A. Metallinou, F. Eyben, B. Schuller, and S. S. Narayanan. 2010. Context-sensitive multimodal emotion recognition from speech and facial expression using bidirectional LSTM modeling. In Proceedings of the 11th Annual Conference of the International Speech Communication Association (INTERSPEECH'10). 2362--2365.
Martin Wollmer , Felix Weninger , Tobias Knaup , Bjorn Schuller , Congkai Sun , Kenji Sagae , Louis-Philippe Morency, YouTube Movie Reviews: Sentiment Analysis in an Audio-Visual Context, IEEE Intelligent Systems, v.28 n.3, p.46-53, May 2013[doi>10.1109/MIS.2013.34]
Chung-Hsien Wu , Wei-Bin Liang, Emotion Recognition of Affective Speech Based on Multiple Classifiers Using Acoustic-Prosodic Information and Semantic Labels, IEEE Transactions on Affective Computing, v.2 n.1, p.10-21, January 2011[doi>10.1109/T-AFFC.2010.16]
Zhihong Zeng , Yuxiao Hu , Yun Fu , Thomas S. Huang , Glenn I. Roisman , Zhen Wen, Audio-visual emotion recognition in adult attachment interview, Proceedings of the 8th international conference on Multimodal interfaces, November 02-04, 2006, Banff, Alberta, Canada[doi>10.1145/1180995.1181028]
Zhihong Zeng , Maja Pantic , Glenn I. Roisman , Thomas S. Huang, A Survey of Affect Recognition Methods: Audio, Visual, and Spontaneous Expressions, IEEE Transactions on Pattern Analysis and Machine Intelligence, v.31 n.1, p.39-58, January 2009[doi>10.1109/TPAMI.2008.52]
Zhihong Zeng , Jilin Tu , Ming Liu , Thomas S. Huang, Multi-stream confidence analysis for audio-visual affect recognition, Proceedings of the First international conference on Affective Computing and Intelligent Interaction, October 22-24, 2005, Beijing, China[doi>10.1007/11573548_123]
Z. Zeng , J. Tu , M. Liu , T. S. Huang , B. Pianfetti , D. Roth , S. Levinson, Audio-Visual Affect Recognition, IEEE Transactions on Multimedia, v.9 n.2, p.424-428, February 2007[doi>10.1109/TMM.2006.886310]
